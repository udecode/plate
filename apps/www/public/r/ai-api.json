{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "ai-api",
  "type": "registry:file",
  "dependencies": [
    "@ai-sdk/openai@1.3.23",
    "ai@4.3.19",
    "@ai-sdk/provider@1.1.3",
    "@ai-sdk/provider-utils@2.2.8"
  ],
  "registryDependencies": [
    "https://platejs.org/r/copilot-api",
    "https://platejs.org/r/markdown-joiner-transform"
  ],
  "files": [
    {
      "path": "src/registry/app/api/ai/command/route.ts",
      "content": "import type { ChatMessage, ToolName } from '@platejs/ai/react';\nimport type { NextRequest } from 'next/server';\n\nimport { createOpenAI } from '@ai-sdk/openai';\nimport {\n  convertToModelMessages,\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n  generateObject,\n  streamObject,\n  streamText,\n} from 'ai';\nimport { NextResponse } from 'next/server';\nimport { nanoid } from 'platejs';\nimport { z } from 'zod/v3';\n\nimport { markdownJoinerTransform } from '@/registry/lib/markdown-joiner-transform';\n\nconst commentSystem = `\\\nYou are a document review assistant.  \nYou will receive an MDX document wrapped in <block id=\"...\"> content </block> tags.  \n\nYour task:  \n- Read the content of all blocks and provide comments.  \n- For each comment, generate a JSON object:  \n  - blockId: the id of the block being commented on.\n  - content: the original document fragment that needs commenting.\n  - comments: a brief comment or explanation for that fragment.\n\nRules:\n- The content field must be the original content inside the block tag. The returned content must not include the block tags, but should retain other MDX tags.\n- The content field can be the entire block, a small part within a block, or span multiple blocks. If spanning multiple blocks, separate them with two \\n\\n.\n- Important: If a comment spans multiple blocks, use the id of the **first** block.\n`;\n\nexport async function POST(req: NextRequest) {\n  const { apiKey: key, commentPrompt, messages, system } = await req.json();\n\n  const apiKey = key || process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return NextResponse.json(\n      { error: 'Missing OpenAI API key.' },\n      { status: 401 }\n    );\n  }\n\n  const openai = createOpenAI({ apiKey });\n\n  try {\n    const stream = createUIMessageStream<ChatMessage>({\n      execute: async ({ writer }) => {\n        const lastUserMessage = messages.findLast(\n          (message: any) => message.role === 'user'\n        );\n\n        const { object: toolName } = await generateObject({\n          enum: ['generate', 'edit', 'comment'],\n          model: openai('gpt-4o'),\n          output: 'enum',\n          prompt: `User message:\n        ${JSON.stringify(lastUserMessage)}`,\n          system: `\n        You are a strict classifier. Classify the user's last request as \"generate\", \"edit\", or \"comment\".\n        \n        Priority rules:\n        1. Default is \"generate\". Any open question, idea request, or creation request â†’ \"generate\".\n        2. Only return \"edit\" if the user provides original text (or a selection of text) AND asks to change, rephrase, translate, or shorten it.\n        3. Only return \"comment\" if the user explicitly asks for comments, feedback, annotations, or review. Do not infer \"comment\" implicitly.\n        \n        Return only one enum value with no explanation.\n        `,\n        });\n\n        writer.write({\n          data: toolName as ToolName,\n          type: 'data-toolName',\n        });\n\n        if (toolName === 'generate') {\n          const gen = streamText({\n            experimental_transform: markdownJoinerTransform(),\n            maxOutputTokens: 2048,\n            messages: convertToModelMessages(messages),\n            model: openai('gpt-4o-mini'),\n            system: system,\n          });\n\n          writer.merge(gen.toUIMessageStream({ sendFinish: false }));\n        }\n\n        if (toolName === 'edit') {\n          // TODO\n          const edit = streamText({\n            experimental_transform: markdownJoinerTransform(),\n            maxOutputTokens: 2048,\n            messages: convertToModelMessages(messages),\n            model: openai('gpt-4o-mini'),\n            system: system,\n          });\n\n          writer.merge(edit.toUIMessageStream({ sendFinish: false }));\n        }\n\n        if (toolName === 'comment') {\n          const { elementStream } = streamObject({\n            maxOutputTokens: 2048,\n            model: openai('gpt-4o-mini'),\n            output: 'array',\n            prompt: commentPrompt,\n            schema: z\n              .object({\n                blockId: z\n                  .string()\n                  .describe(\n                    'The id of the starting block. If the comment spans multiple blocks, use the id of the first block.'\n                  ),\n                comment: z\n                  .string()\n                  .describe(\n                    'A brief comment or explanation for this fragment.'\n                  ),\n                content: z\n                  .string()\n                  .describe(\n                    'The original document fragment to be commented on. Do not modify it in any way.'\n                  ),\n              })\n              .describe('A single comment object'),\n            system: commentSystem,\n          });\n\n          // Create a single message ID for the entire comment stream\n\n          for await (const comment of elementStream) {\n            const commentDataId = nanoid();\n            // Send each comment as a delta\n\n            writer.write({\n              id: commentDataId,\n              data: comment,\n              type: 'data-comment',\n            });\n          }\n\n          return;\n        }\n      },\n    });\n\n    return createUIMessageStreamResponse({ stream });\n  } catch {\n    return NextResponse.json(\n      { error: 'Failed to process AI request' },\n      { status: 500 }\n    );\n  }\n}\n",
      "type": "registry:file",
      "target": "app/api/ai/command/route.ts"
    }
  ]
}