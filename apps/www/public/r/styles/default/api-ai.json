{
  "dependencies": [
    "@ai-sdk/openai",
    "ai"
  ],
  "files": [
    {
      "path": "app/api/ai/command/route.ts",
      "content": "import type { TextStreamPart, ToolSet } from 'ai';\nimport type { NextRequest } from 'next/server';\n\nimport { createOpenAI } from '@ai-sdk/openai';\nimport { InvalidArgumentError } from '@ai-sdk/provider';\nimport { delay as originalDelay } from '@ai-sdk/provider-utils';\nimport { convertToCoreMessages, streamText } from 'ai';\nimport { NextResponse } from 'next/server';\n\n/**\n * Detects the first chunk in a buffer.\n *\n * @param buffer - The buffer to detect the first chunk in.\n * @returns The first detected chunk, or `undefined` if no chunk was detected.\n */\nexport type ChunkDetector = (buffer: string) => string | null | undefined;\n\ntype delayer = (buffer: string) => number;\n\n/**\n * Smooths text streaming output.\n *\n * @param delayInMs - The delay in milliseconds between each chunk. Defaults to\n *   10ms. Can be set to `null` to skip the delay.\n * @param chunking - Controls how the text is chunked for streaming. Use \"word\"\n *   to stream word by word (default), \"line\" to stream line by line, or provide\n *   a custom RegExp pattern for custom chunking.\n * @returns A transform stream that smooths text streaming output.\n */\nexport function smoothStream<TOOLS extends ToolSet>({\n  _internal: { delay = originalDelay } = {},\n  chunking = 'word',\n  delayInMs = 10,\n}: {\n  /** Internal. For test use only. May change without notice. */\n  _internal?: {\n    delay?: (delayInMs: number | null) => Promise<void>;\n  };\n  chunking?: ChunkDetector | RegExp | 'line' | 'word';\n  delayInMs?: delayer | number | null;\n} = {}): (options: {\n  tools: TOOLS;\n}) => TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>> {\n  let detectChunk: ChunkDetector;\n\n  if (typeof chunking === 'function') {\n    detectChunk = (buffer) => {\n      const match = chunking(buffer);\n\n      if (match == null) {\n        return null;\n      }\n\n      if (match.length === 0) {\n        throw new Error(`Chunking function must return a non-empty string.`);\n      }\n\n      if (!buffer.startsWith(match)) {\n        throw new Error(\n          `Chunking function must return a match that is a prefix of the buffer. Received: \"${match}\" expected to start with \"${buffer}\"`\n        );\n      }\n\n      return match;\n    };\n  } else {\n    const chunkingRegex =\n      typeof chunking === 'string' ? CHUNKING_REGEXPS[chunking] : chunking;\n\n    if (chunkingRegex == null) {\n      throw new InvalidArgumentError({\n        argument: 'chunking',\n        message: `Chunking must be \"word\" or \"line\" or a RegExp. Received: ${chunking}`,\n      });\n    }\n\n    detectChunk = (buffer) => {\n      const match = chunkingRegex.exec(buffer);\n\n      if (!match) {\n        return null;\n      }\n\n      return buffer.slice(0, match.index) + match?.[0];\n    };\n  }\n\n  return () => {\n    let buffer = '';\n\n    return new TransformStream<TextStreamPart<TOOLS>, TextStreamPart<TOOLS>>({\n      async transform(chunk, controller) {\n        if (chunk.type !== 'text-delta') {\n          console.log(buffer, 'finished');\n\n          if (buffer.length > 0) {\n            controller.enqueue({ textDelta: buffer, type: 'text-delta' });\n            buffer = '';\n          }\n\n          controller.enqueue(chunk);\n          return;\n        }\n\n        buffer += chunk.textDelta;\n\n        let match;\n\n        while ((match = detectChunk(buffer)) != null) {\n          controller.enqueue({ textDelta: match, type: 'text-delta' });\n          buffer = buffer.slice(match.length);\n\n          const _delayInMs =\n            typeof delayInMs === 'number'\n              ? delayInMs\n              : (delayInMs?.(buffer) ?? 10);\n\n          await delay(_delayInMs);\n        }\n      },\n    });\n  };\n}\n\nconst CHUNKING_REGEXPS = {\n  line: /\\n+/m,\n  list: /.{8}/m,\n  word: /\\S+\\s+/m,\n};\n\nexport async function POST(req: NextRequest) {\n  const { apiKey: key, messages, model = 'gpt-4o', system } = await req.json();\n\n  const apiKey = key || process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return NextResponse.json(\n      { error: 'Missing OpenAI API key.' },\n      { status: 401 }\n    );\n  }\n\n  const openai = createOpenAI({ apiKey });\n\n  let isInCodeBlock = false;\n  let isInTable = false;\n  let isInList = false;\n  let isInLink = false;\n  try {\n    const result = streamText({\n      experimental_transform: smoothStream({\n        chunking: (buffer) => {\n          // Check for code block markers\n          if (/```[^\\s]+/.test(buffer)) {\n            isInCodeBlock = true;\n          } else if (isInCodeBlock && buffer.includes('```')) {\n            isInCodeBlock = false;\n          }\n          // test case: should not deserialize link with markdown syntax\n          if (buffer.includes('http')) {\n            isInLink = true;\n          } else if (buffer.includes('https')) {\n            isInLink = true;\n          } else if (buffer.includes('\\n') && isInLink) {\n            isInLink = false;\n          }\n          if (buffer.includes('*') || buffer.includes('-')) {\n            isInList = true;\n          } else if (buffer.includes('\\n') && isInList) {\n            isInList = false;\n          }\n          // Simple table detection: enter on |, exit on double newline\n          if (!isInTable && buffer.includes('|')) {\n            isInTable = true;\n          } else if (isInTable && buffer.includes('\\n\\n')) {\n            isInTable = false;\n          }\n\n          // Use line chunking for code blocks and tables, word chunking otherwise\n          // Choose the appropriate chunking strategy based on content type\n          let match;\n\n          if (isInCodeBlock || isInTable || isInLink) {\n            // Use line chunking for code blocks and tables\n            match = CHUNKING_REGEXPS.line.exec(buffer);\n          } else if (isInList) {\n            // Use list chunking for lists\n            match = CHUNKING_REGEXPS.list.exec(buffer);\n          } else {\n            // Use word chunking for regular text\n            match = CHUNKING_REGEXPS.word.exec(buffer);\n          }\n          if (!match) {\n            return null;\n          }\n\n          return buffer.slice(0, match.index) + match?.[0];\n        },\n        delayInMs: () => (isInCodeBlock || isInTable ? 100 : 30),\n      }),\n      maxTokens: 2048,\n      messages: convertToCoreMessages(messages),\n      model: openai('gpt-4o'),\n      system: system,\n    });\n\n    return result.toDataStreamResponse();\n  } catch {\n    return NextResponse.json(\n      { error: 'Failed to process AI request' },\n      { status: 500 }\n    );\n  }\n}\n",
      "type": "registry:lib",
      "target": "app/api/ai/command/route.ts"
    },
    {
      "path": "app/api/ai/copilot/route.ts",
      "content": "import type { NextRequest } from 'next/server';\n\nimport { createOpenAI } from '@ai-sdk/openai';\nimport { generateText } from 'ai';\nimport { NextResponse } from 'next/server';\n\nexport async function POST(req: NextRequest) {\n  const {\n    apiKey: key,\n    model = 'gpt-4o-mini',\n    prompt,\n    system,\n  } = await req.json();\n\n  const apiKey = key || process.env.OPENAI_API_KEY;\n\n  if (!apiKey) {\n    return NextResponse.json(\n      { error: 'Missing OpenAI API key.' },\n      { status: 401 }\n    );\n  }\n\n  const openai = createOpenAI({ apiKey });\n\n  try {\n    const result = await generateText({\n      abortSignal: req.signal,\n      maxTokens: 50,\n      model: openai(model),\n      prompt: prompt,\n      system,\n      temperature: 0.7,\n    });\n\n    return NextResponse.json(result);\n  } catch (error: any) {\n    if (error.name === 'AbortError') {\n      return NextResponse.json(null, { status: 408 });\n    }\n\n    return NextResponse.json(\n      { error: 'Failed to process AI request' },\n      { status: 500 }\n    );\n  }\n}\n",
      "type": "registry:lib",
      "target": "app/api/ai/copilot/route.ts"
    }
  ],
  "name": "api-ai",
  "registryDependencies": [],
  "type": "registry:lib",
  "$schema": "https://platejs.org/schema/registry-item.json",
  "author": "udecode (https://platejs.org)"
}